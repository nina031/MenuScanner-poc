{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal :\n",
    "\n",
    "* Construction d'un fichier json structurant l'ensemble du menu avec :\n",
    "    * separation en sections (entrées, plats principaux, desserts ...)\n",
    "    * Identification des plats individuels\n",
    "    * Extraction des prix\n",
    "    * Taguer tous les plats selon le regime alimentaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "\n",
    "claude_api_key = os.environ.get('claude_api_key')\n",
    "gpt_api_key = os.environ.get('gpt_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcello_ocr_result_path = \"../data/raw_extracted/Azure_doc_intelligence/result_OCR_marcello.txt\"\n",
    "prima_ocr_result_path = \"../data/raw_extracted/Azure_doc_intelligence/result_OCR_prima.txt\"\n",
    "output_dir = '../data/segmented_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuration du resultat de l'OCR en utilisant le LLM Claude Haiku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_menu_openai(ocr_text, prompt,api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": ocr_text}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_menu_claude(ocr_text, prompt,api_key):\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",  # ou \"claude-3-7-sonnet-20250219\" pour le plus récent\n",
    "            max_tokens=8192,\n",
    "            temperature=0,\n",
    "            system=prompt,  # Le prompt système va ici, pas dans les messages\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": ocr_text}\n",
    "            ]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response):\n",
    "    \"\"\"\n",
    "    Version minimaliste pour nettoyer les réponses OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        response (dict ou str): Réponse de l'API OpenAI\n",
    "        \n",
    "    Returns:\n",
    "        dict: Menu en JSON\n",
    "    \"\"\"\n",
    "    # Convertir en dict si c'est une string\n",
    "    if isinstance(response, str):\n",
    "        response = json.loads(response)\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition du prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Analyse ce texte OCR de menu et retourne uniquement un JSON valide suivant cette structure:\n",
    "\n",
    "{{\n",
    "  \"menu\": {{\n",
    "    \"sections\": [\n",
    "      {{\n",
    "        \"name\": \"nom_section\",\n",
    "        \"items\": [\n",
    "          {{\n",
    "            \"name\": \"nom_plat\",\n",
    "            \"price\": {{\"value\": 12.50, \"currency\": null}},\n",
    "            \"description\": \"description_complète\",\n",
    "            \"ingredients\": [\"ingrédient1\", \"ingrédient2\"],\n",
    "            \"dietary\": [\"végétarien\"]\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Texte OCR: {ocr_text}\n",
    "\n",
    "Instructions:\n",
    "1. Identifie automatiquement les sections (entrées, plats, desserts, pizzas, boissons, etc.)\n",
    "2. Pour chaque item: nom, prix, description, ingrédients (déduis-les de la description si nécessaire)\n",
    "3. Prix: utilise uniquement €, $, £, CHF pour currency. Si autre chose ou illisible, mets null\n",
    "\n",
    "IMPORTANT - Régimes alimentaires (sois très prudent):\n",
    "- Si tu as un grand doute, laisse dietary vide []\n",
    "- Règles strictes:\n",
    "  * \"végétarien\": AUCUNE viande, poisson, fruits de mer (mais œufs/lait OK)\n",
    "  * \"végétalien\": AUCUN produit animal (pas de viande, poisson, œufs, lait, miel, beurre)\n",
    "  * \"sans_gluten\": AUCUN blé, orge, seigle, avoine (attention aux sauces, panure)\n",
    "  * \"sans_lactose\": AUCUN lait, crème, fromage, beurre, yaourt\n",
    "\n",
    "ATTENTION - VIANDES (jamais végétarien):\n",
    "- Jambon, jambon blanc, jambon cru, prosciutto = VIANDE\n",
    "- Bacon, lardons, pancetta = VIANDE  \n",
    "- Saucisse, chorizo, pepperoni = VIANDE\n",
    "- Salami, coppa, bresaola = VIANDE\n",
    "- Bœuf, porc, agneau, veau = VIANDE\n",
    "- Poulet, canard, dinde = VIANDE\n",
    "\n",
    "Exemples:\n",
    "\n",
    "VÉGÉTARIEN + VÉGÉTALIEN:\n",
    "- Salade verte simple = [\"végétarien\", \"végétalien\"]\n",
    "- Légumes grillés sans sauce = [\"végétarien\", \"végétalien\"] \n",
    "- Frites maison = [\"végétarien\", \"végétalien\"]\n",
    "- Soupe de légumes (bouillon végétal) = [\"végétarien\", \"végétalien\"]\n",
    "\n",
    "VÉGÉTARIEN SEULEMENT:\n",
    "- Pâtes au beurre = [\"végétarien\"] (beurre = produit laitier)\n",
    "- Pizza margherita = [\"végétarien\"] (fromage = produit laitier)\n",
    "- Omelette = [\"végétarien\"] (œufs OK pour végétarien)\n",
    "\n",
    "SANS GLUTEN SEULEMENT:\n",
    "- Steak grillé nature = [\"sans_gluten\"] (pas de panure ni sauce)\n",
    "- Salade de riz = [\"sans_gluten\"] (riz OK)\n",
    "- Poisson grillé nature = [\"sans_gluten\"]\n",
    "\n",
    "SANS LACTOSE SEULEMENT:\n",
    "- Pâtes à l'huile d'olive = [\"sans_lactose\"] (pas de beurre/fromage)\n",
    "- Viande grillée nature = [\"sans_lactose\"]\n",
    "\n",
    "COMBINAISONS:\n",
    "- Salade de quinoa aux légumes = [\"végétarien\", \"végétalien\", \"sans_gluten\", \"sans_lactose\"]\n",
    "- Riz sauté aux légumes = [\"végétarien\", \"végétalien\", \"sans_gluten\", \"sans_lactose\"]\n",
    "- Steak frites = [\"sans_gluten\", \"sans_lactose\"] (si frites maison)\n",
    "IMPORTANT : il faut inclure le resultat complet (tous les elements presents dans le texte OCR)\n",
    "Retourne uniquement le JSON, sans texte additionnel.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Marcello menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(marcello_ocr_result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    marcello_ocr_result = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_marcello = analyze_menu_openai(marcello_ocr_result, prompt,openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_marcello = analyze_menu_claude(marcello_ocr_result, prompt,claude_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_result_marcello = clean_response(result_marcello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du resultat dans un fichier\n",
    "with open(output_dir + \"/result_LLM_sonnet_marcello\", \"w\") as file: \n",
    "        json.dump(cleaned_result_marcello, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Prima lova menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prima_ocr_result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    prima_ocr_result = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_prima = analyze_menu_openai(prima_ocr_result, prompt,openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prima = analyze_menu_claude(prima_ocr_result, prompt,claude_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_result_prima = clean_response(result_prima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du resultat dans un fichier\n",
    "with open(output_dir + \"/result_LLM_sonnet_prima\", \"w\") as file: \n",
    "        json.dump(cleaned_result_prima, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Le modele Haiku de Claude ne peut pas gerer les gros menu a cause de la limite de tokens\n",
    "* gpt-4o-mini n'est pas limité par la limite de token dans notre cas d'usage mais le temps de traitement dure plus de 2 min pour les gros menu et 22 secondes pour les petit menu (2 fois plus lent que claude haiku)\n",
    "* resultats legerement superieur pour claude haiku\n",
    "* Le modele presentant les meilleurs ressultats pour le moment c'est le modele sonnet de Claude (plus rapide, plus performant, peut supporter la limite de toekn pour notre cas d'usage)\n",
    "* Point d'attention : bien que sonnet presente des bons resultats, les modeles sont trop lent. Trouver une solution.\n",
    "* Piste a explorer : \n",
    "*   Tester le streaming, refaire le prompt pour que le modele nous envoie un format jsonL pour pas avoir de probleme de format de la reponse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement par sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "claude_api_key = os.environ.get('claude_api_key')\n",
    "\n",
    "client = Anthropic(api_key=claude_api_key)\n",
    "\n",
    "def call_claude(text: str, prompt: str) -> str:\n",
    "   response = client.messages.create(\n",
    "       model=\"claude-3-5-sonnet-20241022\",\n",
    "       max_tokens=2000,\n",
    "       temperature=0,\n",
    "       system=prompt,\n",
    "       messages=[{\"role\": \"user\", \"content\": text}]\n",
    "   )\n",
    "   return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Prompt pour détecter les sections ET le titre\n",
    "DETECT_SECTIONS_PROMPT = \"\"\"Analyse ce texte OCR de menu et retourne uniquement un JSON avec les noms des sections et le titre du restaurant/menu.\n",
    "\n",
    "Format EXACT:\n",
    "{\n",
    " \"menu_title\": \"Nom du Restaurant/Menu\",\n",
    " \"sections\": [\"SECTION1\", \"SECTION2\", \"SECTION3\"]\n",
    "}\n",
    "\n",
    "Instructions:\n",
    "1. Identifie le titre/nom du restaurant (généralement en haut du menu)\n",
    "2. Identifie automatiquement toutes les sections du menu (entrées, plats, desserts, pizzas, boissons, etc.)\n",
    "3. GARDE EXACTEMENT les noms de sections comme ils apparaissent dans le texte OCR - ne les traduis PAS, ne les modifie PAS\n",
    "4. Ne retourne QUE le JSON, rien d'autre\"\"\"\n",
    "\n",
    "def detect_sections_and_title(ocr_text: str) -> tuple:\n",
    "   response = call_claude(ocr_text, DETECT_SECTIONS_PROMPT)\n",
    "   \n",
    "   try:\n",
    "       # Essayer de parser directement\n",
    "       data = json.loads(response)\n",
    "       return data[\"sections\"], data[\"menu_title\"]\n",
    "   except json.JSONDecodeError:\n",
    "       # Chercher le JSON dans la réponse\n",
    "       json_match = re.search(r'\\{[^}]*\"menu_title\"[^}]*\"sections\"[^}]*\\}', response)\n",
    "       if json_match:\n",
    "           try:\n",
    "               json_str = json_match.group()\n",
    "               print(f\"JSON extrait: {json_str}\")\n",
    "               data = json.loads(json_str)\n",
    "               return data[\"sections\"], data[\"menu_title\"]\n",
    "           except:\n",
    "               print(\"❌ Erreur parsing JSON extrait\")\n",
    "       \n",
    "       # Fallback\n",
    "       sections = re.findall(r'\"([A-Z][A-Z\\sÀ-Ü]*)\"', response)\n",
    "       valid_sections = [s for s in sections if len(s.strip()) >= 3]\n",
    "       return valid_sections, \"Menu\"\n",
    "\n",
    "# Test\n",
    "sections, menu_title = detect_sections_and_title(prima_ocr_result)\n",
    "print(\"Titre du menu:\", menu_title)\n",
    "print(\"Sections détectées:\", sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Étape 2 - Extraire le contenu d'une section (sans le nom) - Version corrigée\n",
    "import re\n",
    "\n",
    "def extract_section_content(ocr_text: str, section_name: str, all_sections: list) -> str:\n",
    "    lines = ocr_text.split('\\n')\n",
    "    content = []\n",
    "    capturing = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Vérifier si c'est le début de notre section (mot entier avec frontières)\n",
    "        if re.search(r'\\b' + re.escape(section_name.upper()) + r'\\b', line.upper()):\n",
    "            capturing = True\n",
    "            # Ne pas ajouter la ligne avec le nom de section\n",
    "            continue\n",
    "        elif capturing:\n",
    "            # Arrêter si on trouve une autre section de la liste détectée (mot entier)\n",
    "            if any(re.search(r'\\b' + re.escape(s.upper()) + r'\\b', line.upper()) for s in all_sections if s != section_name):\n",
    "                break\n",
    "            content.append(line)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "# Test - Extraire toutes les sections dans un JSON\n",
    "sections_with_content = []\n",
    "\n",
    "for section in sections:\n",
    "    content = extract_section_content(prima_ocr_result, section, sections)\n",
    "    sections_with_content.append({\n",
    "        \"name\": section,\n",
    "        \"content\": content\n",
    "    })\n",
    "\n",
    "# Afficher le résultat JSON\n",
    "result = {\"sections\": sections_with_content}\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Étape 3 - Analyser chaque section avec temps de traitement\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "def clean_section_name_for_filename(section_name: str) -> str:\n",
    "    \"\"\"Nettoie le nom de section pour créer un nom de fichier valide.\"\"\"\n",
    "    # Enlever les caractères spéciaux et espaces\n",
    "    clean_name = re.sub(r'[^\\w\\s-]', '', section_name)\n",
    "    # Remplacer les espaces par des underscores\n",
    "    clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "    # Convertir en minuscules\n",
    "    clean_name = clean_name.lower().strip('_')\n",
    "    return clean_name\n",
    "\n",
    "def analyze_section(section_content: str, section_name: str) -> dict:\n",
    "    # Prompt modifié pour corriger les noms de sections\n",
    "    ANALYZE_SECTION_PROMPT = f\"\"\"Analyse cette section de menu nommée \"{section_name}\" et retourne uniquement un JSON valide suivant cette structure:\n",
    "\n",
    "{{\n",
    "  \"name\": \"nom_section_corrigé\",\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"name\": \"nom_plat\",\n",
    "      \"price\": {{\"value\": 12.50, \"currency\": \"€\"}},\n",
    "      \"description\": \"description_complète\",\n",
    "      \"ingredients\": [\"ingrédient1\", \"ingrédient2\"],\n",
    "      \"dietary\": [\"végétarien\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Instructions:\n",
    "1. CORRIGE les erreurs OCR évidentes dans le nom de section \"{section_name}\":\n",
    "   - \"PRZE\" → \"PIZZE\"\n",
    "   - \"DOLC\" → \"DOLCI\"\n",
    "   - \"ANTPASTI\" → \"ANTIPASTI\"\n",
    "   - \"NSALATE\" → \"INSALATE\"\n",
    "   - \"CARNE\" → garde \"CARNE\" (correct)\n",
    "   - \"PASTA\" → garde \"PASTA\" (correct)\n",
    "   - etc.\n",
    "   Utilise le nom corrigé dans le champ \"name\" du JSON\n",
    "2. Pour chaque item: nom, prix, description, ingrédients (déduis-les de la description si nécessaire)\n",
    "3. Prix: utilise uniquement €, $, £, CHF pour currency. Si autre chose ou illisible, mets null\n",
    "4. DÉTECTION ET TRADUCTION DE LANGUE:\n",
    "   - Détecte la langue majoritaire du menu\n",
    "   - Si langue du menu = français → PAS de traduction\n",
    "   - Si langue du menu = langue avec même alphabet que l'utilisateur → traduis les descriptions MAIS garde les spécialités/ingrédients authentiques en langue originale\n",
    "   - Si langue du menu = langue avec alphabet différent de l'utilisateur → TRADUIS TOUT car l'utilisateur ne peut pas lire ces caractères\n",
    "   \n",
    "    Logique par type d'alphabet:\n",
    "   \n",
    "   MÊME FAMILLE D'ALPHABET (garde les spécialités):\n",
    "   - Latin vers Latin: Italien→Français, Espagnol→Anglais, etc.\n",
    "   - Cyrillique vers Cyrillique: Russe→Bulgare, etc.\n",
    "   - Arabe vers Arabe: Arabe→Persan, etc.\n",
    "   \n",
    "   ALPHABETS DIFFÉRENTS (traduis tout):\n",
    "   - Latin vers Chinois: \"Carbonara\" → \"卡邦纳拉意面\"\n",
    "   - Chinois vers Latin: \"宫保鸡丁\" → \"Poulet Gong Bao\"\n",
    "   - Arabe vers Latin: \"كباب\" → \"Kebab\"\n",
    "   - Japonais vers Latin: \"寿司\" → \"Sushi\"\n",
    "   \n",
    "   Exemples de spécialités à GARDER (même alphabet):\n",
    "   - Italien→Français: garde \"mozzarella di bufala\", \"parmigiano\"\n",
    "   - Français→Anglais: garde \"coq au vin\", \"bouillabaisse\"\n",
    "   - Espagnol→Italien: garde \"jamón ibérico\", \"paella\"\n",
    "\n",
    "IMPORTANT - Régimes alimentaires (sois très prudent):\n",
    "- Si tu as un grand doute, laisse dietary vide []\n",
    "- Règles strictes:\n",
    "  * \"végétarien\": AUCUNE viande, poisson, fruits de mer (mais œufs/lait OK)\n",
    "  * \"végétalien\": AUCUN produit animal (pas de viande, poisson, œufs, lait, miel, beurre)\n",
    "  * \"sans_gluten\": AUCUN blé, orge, seigle, avoine (attention aux sauces, panure)\n",
    "  * \"sans_lactose\": AUCUN lait, crème, fromage, beurre, yaourt\n",
    "\n",
    "ATTENTION - VIANDES (jamais végétarien):\n",
    "- Jambon, jambon blanc, jambon cru, prosciutto = VIANDE\n",
    "- Bacon, lardons, pancetta = VIANDE  \n",
    "- Saucisse, chorizo, pepperoni = VIANDE\n",
    "- Salami, coppa, bresaola = VIANDE\n",
    "- Bœuf, porc, agneau, veau = VIANDE\n",
    "- Poulet, canard, dinde = VIANDE\n",
    "\n",
    "IMPORTANT: Inclus TOUS les éléments présents dans cette section.\n",
    "Retourne UNIQUEMENT le JSON, sans texte additionnel.\"\"\"\n",
    "\n",
    "    response = call_claude(section_content, ANALYZE_SECTION_PROMPT)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Fallback avec le bon nom de section\n",
    "        return {\"name\": section_name, \"items\": []}\n",
    "\n",
    "# Créer le dossier de sortie pour les sections\n",
    "sections_output_dir = '../data/sections_analyzed'\n",
    "os.makedirs(sections_output_dir, exist_ok=True)\n",
    "\n",
    "# Variables pour le suivi du temps total\n",
    "total_start_time = time.time()\n",
    "all_sections_data = []\n",
    "\n",
    "print(\"🍽️ Début de l'analyse des sections\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Traitement complet - boucle sur le JSON des sections\n",
    "for i, section_data in enumerate(sections_with_content, 1):\n",
    "    section_name = section_data[\"name\"]\n",
    "    section_content = section_data[\"content\"]\n",
    "    \n",
    "    print(f\"[{i}/{len(sections_with_content)}] Traitement: {section_name}\")\n",
    "    \n",
    "    # Mesurer le temps de traitement de cette section\n",
    "    section_start_time = time.time()\n",
    "    \n",
    "    # Passer le nom de section à la fonction\n",
    "    analyzed = analyze_section(section_content, section_name)\n",
    "    \n",
    "    section_end_time = time.time()\n",
    "    section_duration = section_end_time - section_start_time\n",
    "    \n",
    "    print(f\"    ✅ Terminé en {section_duration:.2f}s\")\n",
    "    \n",
    "    # Récupérer le nom corrigé du JSON retourné\n",
    "    corrected_section_name = analyzed.get(\"name\", section_name)\n",
    "    \n",
    "    # Enregistrer avec le nom corrigé\n",
    "    clean_filename = clean_section_name_for_filename(corrected_section_name)\n",
    "    section_filepath = os.path.join(sections_output_dir, f\"{clean_filename}.json\")\n",
    "    \n",
    "    with open(section_filepath, 'w', encoding='utf-8') as file:\n",
    "        json.dump(analyzed, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    all_sections_data.append(analyzed)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calcul du temps total\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "\n",
    "print(f\"⏱️ Temps total: {total_duration:.2f}s\")\n",
    "print(f\"📊 Moyenne par section: {total_duration/len(sections_with_content):.2f}s\")\n",
    "\n",
    "# Résultat final\n",
    "menu = {\n",
    "    \"menu\": {\n",
    "        \"name\": menu_title,\n",
    "        \"sections\": all_sections_data\n",
    "    }\n",
    "}\n",
    "\n",
    "# Enregistrer le menu complet\n",
    "final_menu_path = os.path.join(sections_output_dir, \"menu_complet.json\")\n",
    "with open(final_menu_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(menu, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"💾 Menu complet sauvegardé: {final_menu_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
