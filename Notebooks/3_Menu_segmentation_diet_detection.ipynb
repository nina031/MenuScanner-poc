{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal :\n",
    "\n",
    "* Construction d'un fichier json structurant l'ensemble du menu avec :\n",
    "    * separation en sections (entr√©es, plats principaux, desserts ...)\n",
    "    * Identification des plats individuels\n",
    "    * Extraction des prix\n",
    "    * Taguer tous les plats selon le regime alimentaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "\n",
    "claude_api_key = os.environ.get('claude_api_key')\n",
    "gpt_api_key = os.environ.get('gpt_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcello_ocr_result_path = \"../data/raw_extracted/Azure_doc_intelligence/result_OCR_marcello.txt\"\n",
    "prima_ocr_result_path = \"../data/raw_extracted/Azure_doc_intelligence/result_OCR_prima.txt\"\n",
    "output_dir = '../data/segmented_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuration du resultat de l'OCR en utilisant le LLM Claude Haiku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_menu_openai(ocr_text, prompt,api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": ocr_text}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_menu_claude(ocr_text, prompt,api_key):\n",
    "    client = Anthropic(api_key=api_key)\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",  # ou \"claude-3-7-sonnet-20250219\" pour le plus r√©cent\n",
    "            max_tokens=8192,\n",
    "            temperature=0,\n",
    "            system=prompt,  # Le prompt syst√®me va ici, pas dans les messages\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": ocr_text}\n",
    "            ]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response):\n",
    "    \"\"\"\n",
    "    Version minimaliste pour nettoyer les r√©ponses OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        response (dict ou str): R√©ponse de l'API OpenAI\n",
    "        \n",
    "    Returns:\n",
    "        dict: Menu en JSON\n",
    "    \"\"\"\n",
    "    # Convertir en dict si c'est une string\n",
    "    if isinstance(response, str):\n",
    "        response = json.loads(response)\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition du prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Analyse ce texte OCR de menu et retourne uniquement un JSON valide suivant cette structure:\n",
    "\n",
    "{{\n",
    "  \"menu\": {{\n",
    "    \"sections\": [\n",
    "      {{\n",
    "        \"name\": \"nom_section\",\n",
    "        \"items\": [\n",
    "          {{\n",
    "            \"name\": \"nom_plat\",\n",
    "            \"price\": {{\"value\": 12.50, \"currency\": null}},\n",
    "            \"description\": \"description_compl√®te\",\n",
    "            \"ingredients\": [\"ingr√©dient1\", \"ingr√©dient2\"],\n",
    "            \"dietary\": [\"v√©g√©tarien\"]\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Texte OCR: {ocr_text}\n",
    "\n",
    "Instructions:\n",
    "1. Identifie automatiquement les sections (entr√©es, plats, desserts, pizzas, boissons, etc.)\n",
    "2. Pour chaque item: nom, prix, description, ingr√©dients (d√©duis-les de la description si n√©cessaire)\n",
    "3. Prix: utilise uniquement ‚Ç¨, $, ¬£, CHF pour currency. Si autre chose ou illisible, mets null\n",
    "\n",
    "IMPORTANT - R√©gimes alimentaires (sois tr√®s prudent):\n",
    "- Si tu as un grand doute, laisse dietary vide []\n",
    "- R√®gles strictes:\n",
    "  * \"v√©g√©tarien\": AUCUNE viande, poisson, fruits de mer (mais ≈ìufs/lait OK)\n",
    "  * \"v√©g√©talien\": AUCUN produit animal (pas de viande, poisson, ≈ìufs, lait, miel, beurre)\n",
    "  * \"sans_gluten\": AUCUN bl√©, orge, seigle, avoine (attention aux sauces, panure)\n",
    "  * \"sans_lactose\": AUCUN lait, cr√®me, fromage, beurre, yaourt\n",
    "\n",
    "ATTENTION - VIANDES (jamais v√©g√©tarien):\n",
    "- Jambon, jambon blanc, jambon cru, prosciutto = VIANDE\n",
    "- Bacon, lardons, pancetta = VIANDE  \n",
    "- Saucisse, chorizo, pepperoni = VIANDE\n",
    "- Salami, coppa, bresaola = VIANDE\n",
    "- B≈ìuf, porc, agneau, veau = VIANDE\n",
    "- Poulet, canard, dinde = VIANDE\n",
    "\n",
    "Exemples:\n",
    "\n",
    "V√âG√âTARIEN + V√âG√âTALIEN:\n",
    "- Salade verte simple = [\"v√©g√©tarien\", \"v√©g√©talien\"]\n",
    "- L√©gumes grill√©s sans sauce = [\"v√©g√©tarien\", \"v√©g√©talien\"] \n",
    "- Frites maison = [\"v√©g√©tarien\", \"v√©g√©talien\"]\n",
    "- Soupe de l√©gumes (bouillon v√©g√©tal) = [\"v√©g√©tarien\", \"v√©g√©talien\"]\n",
    "\n",
    "V√âG√âTARIEN SEULEMENT:\n",
    "- P√¢tes au beurre = [\"v√©g√©tarien\"] (beurre = produit laitier)\n",
    "- Pizza margherita = [\"v√©g√©tarien\"] (fromage = produit laitier)\n",
    "- Omelette = [\"v√©g√©tarien\"] (≈ìufs OK pour v√©g√©tarien)\n",
    "\n",
    "SANS GLUTEN SEULEMENT:\n",
    "- Steak grill√© nature = [\"sans_gluten\"] (pas de panure ni sauce)\n",
    "- Salade de riz = [\"sans_gluten\"] (riz OK)\n",
    "- Poisson grill√© nature = [\"sans_gluten\"]\n",
    "\n",
    "SANS LACTOSE SEULEMENT:\n",
    "- P√¢tes √† l'huile d'olive = [\"sans_lactose\"] (pas de beurre/fromage)\n",
    "- Viande grill√©e nature = [\"sans_lactose\"]\n",
    "\n",
    "COMBINAISONS:\n",
    "- Salade de quinoa aux l√©gumes = [\"v√©g√©tarien\", \"v√©g√©talien\", \"sans_gluten\", \"sans_lactose\"]\n",
    "- Riz saut√© aux l√©gumes = [\"v√©g√©tarien\", \"v√©g√©talien\", \"sans_gluten\", \"sans_lactose\"]\n",
    "- Steak frites = [\"sans_gluten\", \"sans_lactose\"] (si frites maison)\n",
    "IMPORTANT : il faut inclure le resultat complet (tous les elements presents dans le texte OCR)\n",
    "Retourne uniquement le JSON, sans texte additionnel.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Marcello menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(marcello_ocr_result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    marcello_ocr_result = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_marcello = analyze_menu_openai(marcello_ocr_result, prompt,openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_marcello = analyze_menu_claude(marcello_ocr_result, prompt,claude_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_result_marcello = clean_response(result_marcello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du resultat dans un fichier\n",
    "with open(output_dir + \"/result_LLM_sonnet_marcello\", \"w\") as file: \n",
    "        json.dump(cleaned_result_marcello, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Prima lova menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prima_ocr_result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    prima_ocr_result = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_prima = analyze_menu_openai(prima_ocr_result, prompt,openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prima = analyze_menu_claude(prima_ocr_result, prompt,claude_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_result_prima = clean_response(result_prima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du resultat dans un fichier\n",
    "with open(output_dir + \"/result_LLM_sonnet_prima\", \"w\") as file: \n",
    "        json.dump(cleaned_result_prima, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Le modele Haiku de Claude ne peut pas gerer les gros menu a cause de la limite de tokens\n",
    "* gpt-4o-mini n'est pas limit√© par la limite de token dans notre cas d'usage mais le temps de traitement dure plus de 2 min pour les gros menu et 22 secondes pour les petit menu (2 fois plus lent que claude haiku)\n",
    "* resultats legerement superieur pour claude haiku\n",
    "* Le modele presentant les meilleurs ressultats pour le moment c'est le modele sonnet de Claude (plus rapide, plus performant, peut supporter la limite de toekn pour notre cas d'usage)\n",
    "* Point d'attention : bien que sonnet presente des bons resultats, les modeles sont trop lent. Trouver une solution.\n",
    "* Piste a explorer : \n",
    "*   Tester le streaming, refaire le prompt pour que le modele nous envoie un format jsonL pour pas avoir de probleme de format de la reponse. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement par sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "claude_api_key = os.environ.get('claude_api_key')\n",
    "\n",
    "client = Anthropic(api_key=claude_api_key)\n",
    "\n",
    "def call_claude(text: str, prompt: str) -> str:\n",
    "   response = client.messages.create(\n",
    "       model=\"claude-3-5-sonnet-20241022\",\n",
    "       max_tokens=2000,\n",
    "       temperature=0,\n",
    "       system=prompt,\n",
    "       messages=[{\"role\": \"user\", \"content\": text}]\n",
    "   )\n",
    "   return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Prompt pour d√©tecter les sections ET le titre\n",
    "DETECT_SECTIONS_PROMPT = \"\"\"Analyse ce texte OCR de menu et retourne uniquement un JSON avec les noms des sections et le titre du restaurant/menu.\n",
    "\n",
    "Format EXACT:\n",
    "{\n",
    " \"menu_title\": \"Nom du Restaurant/Menu\",\n",
    " \"sections\": [\"SECTION1\", \"SECTION2\", \"SECTION3\"]\n",
    "}\n",
    "\n",
    "Instructions:\n",
    "1. Identifie le titre/nom du restaurant (g√©n√©ralement en haut du menu)\n",
    "2. Identifie automatiquement toutes les sections du menu (entr√©es, plats, desserts, pizzas, boissons, etc.)\n",
    "3. GARDE EXACTEMENT les noms de sections comme ils apparaissent dans le texte OCR - ne les traduis PAS, ne les modifie PAS\n",
    "4. Ne retourne QUE le JSON, rien d'autre\"\"\"\n",
    "\n",
    "def detect_sections_and_title(ocr_text: str) -> tuple:\n",
    "   response = call_claude(ocr_text, DETECT_SECTIONS_PROMPT)\n",
    "   \n",
    "   try:\n",
    "       # Essayer de parser directement\n",
    "       data = json.loads(response)\n",
    "       return data[\"sections\"], data[\"menu_title\"]\n",
    "   except json.JSONDecodeError:\n",
    "       # Chercher le JSON dans la r√©ponse\n",
    "       json_match = re.search(r'\\{[^}]*\"menu_title\"[^}]*\"sections\"[^}]*\\}', response)\n",
    "       if json_match:\n",
    "           try:\n",
    "               json_str = json_match.group()\n",
    "               print(f\"JSON extrait: {json_str}\")\n",
    "               data = json.loads(json_str)\n",
    "               return data[\"sections\"], data[\"menu_title\"]\n",
    "           except:\n",
    "               print(\"‚ùå Erreur parsing JSON extrait\")\n",
    "       \n",
    "       # Fallback\n",
    "       sections = re.findall(r'\"([A-Z][A-Z\\s√Ä-√ú]*)\"', response)\n",
    "       valid_sections = [s for s in sections if len(s.strip()) >= 3]\n",
    "       return valid_sections, \"Menu\"\n",
    "\n",
    "# Test\n",
    "sections, menu_title = detect_sections_and_title(prima_ocr_result)\n",
    "print(\"Titre du menu:\", menu_title)\n",
    "print(\"Sections d√©tect√©es:\", sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: √âtape 2 - Extraire le contenu d'une section (sans le nom) - Version corrig√©e\n",
    "import re\n",
    "\n",
    "def extract_section_content(ocr_text: str, section_name: str, all_sections: list) -> str:\n",
    "    lines = ocr_text.split('\\n')\n",
    "    content = []\n",
    "    capturing = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # V√©rifier si c'est le d√©but de notre section (mot entier avec fronti√®res)\n",
    "        if re.search(r'\\b' + re.escape(section_name.upper()) + r'\\b', line.upper()):\n",
    "            capturing = True\n",
    "            # Ne pas ajouter la ligne avec le nom de section\n",
    "            continue\n",
    "        elif capturing:\n",
    "            # Arr√™ter si on trouve une autre section de la liste d√©tect√©e (mot entier)\n",
    "            if any(re.search(r'\\b' + re.escape(s.upper()) + r'\\b', line.upper()) for s in all_sections if s != section_name):\n",
    "                break\n",
    "            content.append(line)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "# Test - Extraire toutes les sections dans un JSON\n",
    "sections_with_content = []\n",
    "\n",
    "for section in sections:\n",
    "    content = extract_section_content(prima_ocr_result, section, sections)\n",
    "    sections_with_content.append({\n",
    "        \"name\": section,\n",
    "        \"content\": content\n",
    "    })\n",
    "\n",
    "# Afficher le r√©sultat JSON\n",
    "result = {\"sections\": sections_with_content}\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: √âtape 3 - Analyser chaque section avec temps de traitement\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "def clean_section_name_for_filename(section_name: str) -> str:\n",
    "    \"\"\"Nettoie le nom de section pour cr√©er un nom de fichier valide.\"\"\"\n",
    "    # Enlever les caract√®res sp√©ciaux et espaces\n",
    "    clean_name = re.sub(r'[^\\w\\s-]', '', section_name)\n",
    "    # Remplacer les espaces par des underscores\n",
    "    clean_name = re.sub(r'\\s+', '_', clean_name)\n",
    "    # Convertir en minuscules\n",
    "    clean_name = clean_name.lower().strip('_')\n",
    "    return clean_name\n",
    "\n",
    "def analyze_section(section_content: str, section_name: str) -> dict:\n",
    "    # Prompt modifi√© pour corriger les noms de sections\n",
    "    ANALYZE_SECTION_PROMPT = f\"\"\"Analyse cette section de menu nomm√©e \"{section_name}\" et retourne uniquement un JSON valide suivant cette structure:\n",
    "\n",
    "{{\n",
    "  \"name\": \"nom_section_corrig√©\",\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"name\": \"nom_plat\",\n",
    "      \"price\": {{\"value\": 12.50, \"currency\": \"‚Ç¨\"}},\n",
    "      \"description\": \"description_compl√®te\",\n",
    "      \"ingredients\": [\"ingr√©dient1\", \"ingr√©dient2\"],\n",
    "      \"dietary\": [\"v√©g√©tarien\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Instructions:\n",
    "1. CORRIGE les erreurs OCR √©videntes dans le nom de section \"{section_name}\":\n",
    "   - \"PRZE\" ‚Üí \"PIZZE\"\n",
    "   - \"DOLC\" ‚Üí \"DOLCI\"\n",
    "   - \"ANTPASTI\" ‚Üí \"ANTIPASTI\"\n",
    "   - \"NSALATE\" ‚Üí \"INSALATE\"\n",
    "   - \"CARNE\" ‚Üí garde \"CARNE\" (correct)\n",
    "   - \"PASTA\" ‚Üí garde \"PASTA\" (correct)\n",
    "   - etc.\n",
    "   Utilise le nom corrig√© dans le champ \"name\" du JSON\n",
    "2. Pour chaque item: nom, prix, description, ingr√©dients (d√©duis-les de la description si n√©cessaire)\n",
    "3. Prix: utilise uniquement ‚Ç¨, $, ¬£, CHF pour currency. Si autre chose ou illisible, mets null\n",
    "4. D√âTECTION ET TRADUCTION DE LANGUE:\n",
    "   - D√©tecte la langue majoritaire du menu\n",
    "   - Si langue du menu = fran√ßais ‚Üí PAS de traduction\n",
    "   - Si langue du menu = langue avec m√™me alphabet que l'utilisateur ‚Üí traduis les descriptions MAIS garde les sp√©cialit√©s/ingr√©dients authentiques en langue originale\n",
    "   - Si langue du menu = langue avec alphabet diff√©rent de l'utilisateur ‚Üí TRADUIS TOUT car l'utilisateur ne peut pas lire ces caract√®res\n",
    "   \n",
    "    Logique par type d'alphabet:\n",
    "   \n",
    "   M√äME FAMILLE D'ALPHABET (garde les sp√©cialit√©s):\n",
    "   - Latin vers Latin: Italien‚ÜíFran√ßais, Espagnol‚ÜíAnglais, etc.\n",
    "   - Cyrillique vers Cyrillique: Russe‚ÜíBulgare, etc.\n",
    "   - Arabe vers Arabe: Arabe‚ÜíPersan, etc.\n",
    "   \n",
    "   ALPHABETS DIFF√âRENTS (traduis tout):\n",
    "   - Latin vers Chinois: \"Carbonara\" ‚Üí \"Âç°ÈÇ¶Á∫≥ÊãâÊÑèÈù¢\"\n",
    "   - Chinois vers Latin: \"ÂÆ´‰øùÈ∏°‰∏Å\" ‚Üí \"Poulet Gong Bao\"\n",
    "   - Arabe vers Latin: \"ŸÉÿ®ÿßÿ®\" ‚Üí \"Kebab\"\n",
    "   - Japonais vers Latin: \"ÂØøÂè∏\" ‚Üí \"Sushi\"\n",
    "   \n",
    "   Exemples de sp√©cialit√©s √† GARDER (m√™me alphabet):\n",
    "   - Italien‚ÜíFran√ßais: garde \"mozzarella di bufala\", \"parmigiano\"\n",
    "   - Fran√ßais‚ÜíAnglais: garde \"coq au vin\", \"bouillabaisse\"\n",
    "   - Espagnol‚ÜíItalien: garde \"jam√≥n ib√©rico\", \"paella\"\n",
    "\n",
    "IMPORTANT - R√©gimes alimentaires (sois tr√®s prudent):\n",
    "- Si tu as un grand doute, laisse dietary vide []\n",
    "- R√®gles strictes:\n",
    "  * \"v√©g√©tarien\": AUCUNE viande, poisson, fruits de mer (mais ≈ìufs/lait OK)\n",
    "  * \"v√©g√©talien\": AUCUN produit animal (pas de viande, poisson, ≈ìufs, lait, miel, beurre)\n",
    "  * \"sans_gluten\": AUCUN bl√©, orge, seigle, avoine (attention aux sauces, panure)\n",
    "  * \"sans_lactose\": AUCUN lait, cr√®me, fromage, beurre, yaourt\n",
    "\n",
    "ATTENTION - VIANDES (jamais v√©g√©tarien):\n",
    "- Jambon, jambon blanc, jambon cru, prosciutto = VIANDE\n",
    "- Bacon, lardons, pancetta = VIANDE  \n",
    "- Saucisse, chorizo, pepperoni = VIANDE\n",
    "- Salami, coppa, bresaola = VIANDE\n",
    "- B≈ìuf, porc, agneau, veau = VIANDE\n",
    "- Poulet, canard, dinde = VIANDE\n",
    "\n",
    "IMPORTANT: Inclus TOUS les √©l√©ments pr√©sents dans cette section.\n",
    "Retourne UNIQUEMENT le JSON, sans texte additionnel.\"\"\"\n",
    "\n",
    "    response = call_claude(section_content, ANALYZE_SECTION_PROMPT)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Fallback avec le bon nom de section\n",
    "        return {\"name\": section_name, \"items\": []}\n",
    "\n",
    "# Cr√©er le dossier de sortie pour les sections\n",
    "sections_output_dir = '../data/sections_analyzed'\n",
    "os.makedirs(sections_output_dir, exist_ok=True)\n",
    "\n",
    "# Variables pour le suivi du temps total\n",
    "total_start_time = time.time()\n",
    "all_sections_data = []\n",
    "\n",
    "print(\"üçΩÔ∏è D√©but de l'analyse des sections\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Traitement complet - boucle sur le JSON des sections\n",
    "for i, section_data in enumerate(sections_with_content, 1):\n",
    "    section_name = section_data[\"name\"]\n",
    "    section_content = section_data[\"content\"]\n",
    "    \n",
    "    print(f\"[{i}/{len(sections_with_content)}] Traitement: {section_name}\")\n",
    "    \n",
    "    # Mesurer le temps de traitement de cette section\n",
    "    section_start_time = time.time()\n",
    "    \n",
    "    # Passer le nom de section √† la fonction\n",
    "    analyzed = analyze_section(section_content, section_name)\n",
    "    \n",
    "    section_end_time = time.time()\n",
    "    section_duration = section_end_time - section_start_time\n",
    "    \n",
    "    print(f\"    ‚úÖ Termin√© en {section_duration:.2f}s\")\n",
    "    \n",
    "    # R√©cup√©rer le nom corrig√© du JSON retourn√©\n",
    "    corrected_section_name = analyzed.get(\"name\", section_name)\n",
    "    \n",
    "    # Enregistrer avec le nom corrig√©\n",
    "    clean_filename = clean_section_name_for_filename(corrected_section_name)\n",
    "    section_filepath = os.path.join(sections_output_dir, f\"{clean_filename}.json\")\n",
    "    \n",
    "    with open(section_filepath, 'w', encoding='utf-8') as file:\n",
    "        json.dump(analyzed, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    all_sections_data.append(analyzed)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calcul du temps total\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "\n",
    "print(f\"‚è±Ô∏è Temps total: {total_duration:.2f}s\")\n",
    "print(f\"üìä Moyenne par section: {total_duration/len(sections_with_content):.2f}s\")\n",
    "\n",
    "# R√©sultat final\n",
    "menu = {\n",
    "    \"menu\": {\n",
    "        \"name\": menu_title,\n",
    "        \"sections\": all_sections_data\n",
    "    }\n",
    "}\n",
    "\n",
    "# Enregistrer le menu complet\n",
    "final_menu_path = os.path.join(sections_output_dir, \"menu_complet.json\")\n",
    "with open(final_menu_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(menu, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Menu complet sauvegard√©: {final_menu_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
